{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How popular are different social movements over time?\n",
    "\n",
    "LSE DS105A - Data for Data Science (2024/25)\n",
    "\n",
    "**Date**: 18/11/24\n",
    "\n",
    "**Author**: Amelia Dunn\n",
    "\n",
    "**Objective**:ðŸŒŸ Pull data files from GDELT API to get popularity of different social movements or events over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soures we looked into:\n",
    "- I tried investigating Reddit data, but you cannot access historical data\n",
    "- Then I tried investigating X (previously known as Twitter), but you could only access the historical data through paying.\n",
    "- We tried querying data from GDELT API, but we were only able to access data from 2014 onward, which we found to be too limiting. On top of this, it provides a seperate json file for each day from 2014 which is alot.\n",
    "- Tryed to get data from Open sanctions and open corporate, but found that this was an API you have to pay for\n",
    "- Now cycling back to GDELT and gathering data only from 2014 onwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## GDELT data:\n",
    "\n",
    "- pulling each days data file from GDELT [website](http://data.gdeltproject.org/events/index.html) and combining them into yearly csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing the data so to not exceed the data limit:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the column names of the data \n",
    "\n",
    "GDELT_COLUMNS = [\n",
    "    \"GLOBALEVENTID\", \"SQLDATE\", \"MonthYear\", \"Year\", \"FractionDate\", \"Actor1Code\", \"Actor1Name\", \n",
    "    \"Actor1CountryCode\", \"Actor1KnownGroupCode\", \"Actor1EthnicCode\", \"Actor1Religion1Code\", \n",
    "    \"Actor1Religion2Code\", \"Actor1Type1Code\", \"Actor1Type2Code\", \"Actor1Type3Code\", \"Actor2Code\", \n",
    "    \"Actor2Name\", \"Actor2CountryCode\", \"Actor2KnownGroupCode\", \"Actor2EthnicCode\", \"Actor2Religion1Code\", \n",
    "    \"Actor2Religion2Code\", \"Actor2Type1Code\", \"Actor2Type2Code\", \"Actor2Type3Code\", \"IsRootEvent\", \n",
    "    \"EventCode\", \"EventBaseCode\", \"EventRootCode\", \"QuadClass\", \"GoldsteinScale\", \"NumMentions\", \n",
    "    \"NumSources\", \"NumArticles\", \"AvgTone\", \"Actor1Geo_Type\", \"Actor1Geo_FullName\", \"Actor1Geo_CountryCode\", \n",
    "    \"Actor1Geo_ADM1Code\", \"Actor1Geo_Lat\", \"Actor1Geo_Long\", \"Actor1Geo_FeatureID\", \"Actor2Geo_Type\", \n",
    "    \"Actor2Geo_FullName\", \"Actor2Geo_CountryCode\", \"Actor2Geo_ADM1Code\", \"Actor2Geo_Lat\", \"Actor2Geo_Long\", \n",
    "    \"Actor2Geo_FeatureID\", \"ActionGeo_Type\", \"ActionGeo_FullName\", \"ActionGeo_CountryCode\", \"ActionGeo_ADM1Code\", \n",
    "    \"ActionGeo_Lat\", \"ActionGeo_Long\", \"ActionGeo_FeatureID\", \"DATEADDED\", \"SOURCEURL\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to download the data and process it (had to include some processing due to issues with the files being too large overall to download all of them before processing) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_process_zip(url, output_dir, retries=3, delay=2):\n",
    "    \"\"\"\n",
    "    Downloads and processes a zip file, adding column headers, filtering for US protest events, \n",
    "    and returns a filtered DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL of the GDELT zip file.\n",
    "        output_dir (str): Directory to store the extracted files.\n",
    "        retries (int): Number of retry attempts on failure.\n",
    "        delay (int): Delay (in seconds) between retries.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed data, or None if the download failed.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "    zip_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    # Try to download the file with retries\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=30)\n",
    "            if response.status_code == 404:\n",
    "                print(f\"File not found (404): {url}\")\n",
    "                return None\n",
    "            elif response.status_code == 200:\n",
    "                with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "                    # Extract the first file from the zip\n",
    "                    for file in z.namelist():\n",
    "                        with z.open(file) as csv_file:\n",
    "                            # Read the CSV file into a DataFrame without headers\n",
    "                            df = pd.read_csv(csv_file, sep='\\t', header=None, low_memory=False)\n",
    "                            \n",
    "                            # Check the number of columns and adjust headers accordingly\n",
    "                            num_columns = df.shape[1]\n",
    "                            if num_columns == len(GDELT_COLUMNS):\n",
    "                                df.columns = GDELT_COLUMNS\n",
    "                            else:\n",
    "                                print(f\"Warning: Column mismatch. Expected {len(GDELT_COLUMNS)} columns, but found {num_columns}.\")\n",
    "                            \n",
    "                            # Filter for US protest events only \n",
    "                            df_filtered = df[(df['Actor1Geo_CountryCode'] == 'US') & (df['EventCode'] == 140)]\n",
    "                            return df_filtered\n",
    "            else:\n",
    "                print(f\"Failed to download {url}. HTTP Status Code: {response.status_code}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error downloading {url}: {e}\")\n",
    "        \n",
    "        print(f\"Retrying in {delay} seconds...\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "    print(f\"Failed to download after {retries} attempts: {url}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funtion to build yearly summaries of the processed daily data:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Even though the data is partially processed, it will be saved in a raw data folder as we will further process the data in NB02. Some processing was nessecary in this notebook to make the file sizes smaller, but this is minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_year_data(start_year, end_year, output_dir=\".../../data/raw\"):\n",
    "    \"\"\"\n",
    "    Processes data for the entire year, one zip file at a time, and saves the result as a single CSV.\n",
    "    \n",
    "    Args:\n",
    "        start_year (int): Start year for the data.\n",
    "        end_year (int): End year for the data.\n",
    "        output_dir (str): Directory to store the extracted and processed data.\n",
    "    \"\"\"\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        print(f\"Processing data for year {year}...\")\n",
    "        year_data = pd.DataFrame()  # To store processed data for the year\n",
    "\n",
    "        # Process each day in the year\n",
    "        for month in range(1, 13):  # Loop over each month\n",
    "            for day in range(1, 32):  # Loop over each day\n",
    "                # Build the URL for the daily file (assuming the GDELT format is daily post 2013)\n",
    "                url = f\"http://data.gdeltproject.org/events/{year}{str(month).zfill(2)}{str(day).zfill(2)}.export.CSV.zip\"\n",
    "                \n",
    "                # Download and process the zip file\n",
    "                df_filtered = download_and_process_zip(url, output_dir)\n",
    "                if df_filtered is not None:\n",
    "                    # Concatenate the filtered data for the day into the year's dataframe\n",
    "                    year_data = pd.concat([year_data, df_filtered], ignore_index=True)\n",
    "                \n",
    "                # Add a small delay between requests\n",
    "                time.sleep(2)\n",
    "\n",
    "        # Save the year's data to a CSV file\n",
    "        if not year_data.empty:\n",
    "            output_file = os.path.join(output_dir, f\"{year}_protest_data.csv\")\n",
    "            year_data.to_csv(output_file, index=False)\n",
    "            print(f\"Year {year} data saved to {output_file}\")\n",
    "        else:\n",
    "            print(f\"No data found for year {year}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for year 2013...\n",
      "File not found (404): http://data.gdeltproject.org/events/20130101.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130102.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130103.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130104.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130105.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130106.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130107.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130108.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130109.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130110.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130111.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130112.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130113.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130114.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130115.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130116.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130117.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130118.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130119.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130120.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130121.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130122.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130123.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130124.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130125.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130126.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130127.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130128.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130129.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130130.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130131.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130201.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130202.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130203.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130204.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130205.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130206.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130207.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130208.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130209.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130210.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130211.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130212.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130213.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130214.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130215.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130216.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130217.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130218.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130219.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130220.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130221.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130222.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130223.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130224.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130225.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130226.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130227.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130228.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130229.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130230.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130231.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130301.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130302.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130303.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130304.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130305.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130306.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130307.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130308.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130309.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130310.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130311.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130312.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130313.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130314.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130315.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130316.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130317.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130318.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130319.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130320.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130321.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130322.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130323.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130324.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130325.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130326.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130327.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130328.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130329.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130330.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130331.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130431.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130631.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130931.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20131131.export.CSV.zip\n",
      "Year 2013 data saved to ../data_amelia/raw/2013_protest_data.csv\n",
      "Processing data for year 2014...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Process data from 2014 to 2023\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mprocess_year_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_year\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2013\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_year\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2023\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m, in \u001b[0;36mprocess_year_data\u001b[0;34m(start_year, end_year, output_dir)\u001b[0m\n\u001b[1;32m     24\u001b[0m             year_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([year_data, df_filtered], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;66;03m# Add a small delay between requests\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Save the year's data to a CSV file\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m year_data\u001b[38;5;241m.\u001b[39mempty:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Process data from 2014 to 2023\n",
    "process_year_data(start_year=2013, end_year=2023)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The function above will take at least 4 or 5 hours to get the data from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling data for 2006 to 2013:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided it was necessary to pull this data after the initial visualations showed that the art data that compared it to did not have much data in the 2010s. Therefore, it was necessary to have social movements data from earlier decades to be able to see some correlation between social movements and art themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDELT column names\n",
    "GDELT_COLUMNS = [\n",
    "    \"GLOBALEVENTID\", \"SQLDATE\", \"MonthYear\", \"Year\", \"FractionDate\", \"Actor1Code\", \"Actor1Name\",\n",
    "    \"Actor1CountryCode\", \"Actor1KnownGroupCode\", \"Actor1EthnicCode\", \"Actor1Religion1Code\",\n",
    "    \"Actor1Religion2Code\", \"Actor1Type1Code\", \"Actor1Type2Code\", \"Actor1Type3Code\", \"Actor2Code\",\n",
    "    \"Actor2Name\", \"Actor2CountryCode\", \"Actor2KnownGroupCode\", \"Actor2EthnicCode\", \"Actor2Religion1Code\",\n",
    "    \"Actor2Religion2Code\", \"Actor2Type1Code\", \"Actor2Type2Code\", \"Actor2Type3Code\", \"IsRootEvent\",\n",
    "    \"EventCode\", \"EventBaseCode\", \"EventRootCode\", \"QuadClass\", \"GoldsteinScale\", \"NumMentions\",\n",
    "    \"NumSources\", \"NumArticles\", \"AvgTone\", \"Actor1Geo_Type\", \"Actor1Geo_FullName\", \"Actor1Geo_CountryCode\",\n",
    "    \"Actor1Geo_ADM1Code\", \"Actor1Geo_Lat\", \"Actor1Geo_Long\", \"Actor1Geo_FeatureID\", \"Actor2Geo_Type\",\n",
    "    \"Actor2Geo_FullName\", \"Actor2Geo_CountryCode\", \"Actor2Geo_ADM1Code\", \"Actor2Geo_Lat\",\n",
    "    \"Actor2Geo_Long\", \"Actor2Geo_FeatureID\", \"ActionGeo_Type\", \"ActionGeo_FullName\",\n",
    "    \"ActionGeo_CountryCode\", \"ActionGeo_ADM1Code\", \"ActionGeo_Lat\", \"ActionGeo_Long\",\n",
    "    \"ActionGeo_FeatureID\", \"DATEADDED\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_process_monthly_zip(url, output_dir):\n",
    "    \"\"\"\n",
    "    Downloads and processes a monthly GDELT zip file, filters for US social movement data, \n",
    "    and returns a DataFrame.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "    zip_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=60)\n",
    "        if response.status_code == 404:\n",
    "            print(f\"File not found (404): {url}\")\n",
    "            return None\n",
    "        elif response.status_code == 200:\n",
    "            with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "                for file in z.namelist():\n",
    "                    with z.open(file) as csv_file:\n",
    "                        # Read in chunks to handle large files\n",
    "                        chunk_list = []\n",
    "                        for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
    "                            chunk.columns = GDELT_COLUMNS[:chunk.shape[1]]\n",
    "                            filtered_chunk = chunk[(chunk['Actor1Geo_CountryCode'] == 'US') & (chunk['EventCode'] == 140)]\n",
    "                            chunk_list.append(filtered_chunk)\n",
    "                        if chunk_list:\n",
    "                            return pd.concat(chunk_list, ignore_index=True)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "    except zipfile.BadZipFile as e:\n",
    "        print(f\"Zip file error: {e}\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_year_data(start_year, end_year, output_dir=\"../../data/raw\"):\n",
    "    \"\"\"\n",
    "    Processes data from 2006 to 2013, combining monthly files into yearly CSVs.\n",
    "    \"\"\"\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        print(f\"Processing data for year {year}...\")\n",
    "        year_data = pd.DataFrame()  # Initialize yearly data storage\n",
    "\n",
    "        for month in range(1, 13):\n",
    "            # Build the URL for the monthly file\n",
    "            url = f\"http://data.gdeltproject.org/events/{year}{str(month).zfill(2)}.zip\"\n",
    "            \n",
    "            # Download and process the monthly file\n",
    "            df_filtered = download_and_process_monthly_zip(url, output_dir)\n",
    "            if df_filtered is not None:\n",
    "                year_data = pd.concat([year_data, df_filtered], ignore_index=True)\n",
    "\n",
    "            # Add a delay to avoid overloading the server\n",
    "            time.sleep(2)\n",
    "\n",
    "        # Save the year's data to a CSV file\n",
    "        if not year_data.empty:\n",
    "            output_file = os.path.join(output_dir, f\"{year}_protest_data.csv\")\n",
    "            year_data.to_csv(output_file, index=False)\n",
    "            print(f\"Year {year} data saved to {output_file}\")\n",
    "        else:\n",
    "            print(f\"No data found for year {year}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for year 2013...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,12,13,14,19,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (5,6,7,8,9,10,11,12,13,14,18,19,21,24,36,37,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (5,6,7,8,9,10,11,12,13,14,18,19,21,24,36,37,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (5,6,7,8,9,10,11,12,13,14,19,21,36,37,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (5,6,7,8,9,10,11,12,13,14,18,19,24,36,37,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,43,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,14,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,13,14,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (7,8,9,10,11,13,14,18,19,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (7,8,9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,14,21,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,14,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (5,6,7,8,9,10,11,12,13,14,19,21,36,37,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (5,6,7,8,9,10,11,12,13,14,19,24,36,37,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,43,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,14,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,12,13,14,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,43,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,14,24,26,27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,13,14,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,43,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,14,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,43,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,12,13,14,18,19,21,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,24,26,27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,14,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,14,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (7,8,9,10,11,13,14,18,19,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (7,8,9,10,11,13,14,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,12,13,14,18,19,21,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14,19,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (5,6,7,8,9,10,11,12,13,14,18,19,24,36,37,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (7,8,9,10,11,13,14,19,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (5,6,7,8,9,10,11,12,13,14,19,21,36,37,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,12,13,14,18,19,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,43,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (5,6,7,8,9,10,11,12,13,14,19,21,24,36,37,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,26,27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,12,13,14,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,10,11,12,13,14,18,19,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (8,9,11,14,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n",
      "/tmp/ipykernel_12958/1900988045.py:46: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(csv_file, sep='\\t', header=None, low_memory=True, chunksize=100000):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found (404): http://data.gdeltproject.org/events/201304.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/201305.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/201306.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/201307.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/201308.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/201309.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/201310.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/201311.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/201312.zip\n",
      "Year 2013 data saved to ../data_amelia/raw/2013_protest_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Run the full processing from 2006 to 2013\n",
    "process_year_data(2006, 2012)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
