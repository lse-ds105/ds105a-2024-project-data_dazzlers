{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How popular are different social movements over time?\n",
    "\n",
    "LSE DS105A - Data for Data Science (2024/25)\n",
    "\n",
    "**Date**: 18/11/24\n",
    "\n",
    "**Author**: Amelia Dunn\n",
    "\n",
    "**Objective**:ðŸŒŸ Pull data files from GDELT API to get popularity of different social movements or events over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soures we looked into:\n",
    "- I tried investigating Reddit data, but you cannot access historical data\n",
    "- Then I tried investigating X (previously known as Twitter), but you could only access the historical data through paying.\n",
    "- We tried querying data from GDELT API, but we were only able to access data from 2014 onward, which we found to be too limiting. On top of this, it provides a seperate json file for each day from 2014 which is alot.\n",
    "- Tryed to get data from Open sanctions and open corporate, but found that this was an API you have to pay for\n",
    "- Now cycling back to GDELT and gathering data only from 2014 onwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")  \n",
    "\n",
    "from data_collection import download_and_process_zip, process_year_data, download_and_process_monthly_zip, Process_year_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## GDELT data:\n",
    "\n",
    "- pulling each days data file from GDELT [website](http://data.gdeltproject.org/events/index.html) and combining them into yearly csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing the data so to not exceed the data limit:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the column names of the data \n",
    "\n",
    "GDELT_COLUMNS = [\n",
    "    \"GLOBALEVENTID\", \"SQLDATE\", \"MonthYear\", \"Year\", \"FractionDate\", \"Actor1Code\", \"Actor1Name\", \n",
    "    \"Actor1CountryCode\", \"Actor1KnownGroupCode\", \"Actor1EthnicCode\", \"Actor1Religion1Code\", \n",
    "    \"Actor1Religion2Code\", \"Actor1Type1Code\", \"Actor1Type2Code\", \"Actor1Type3Code\", \"Actor2Code\", \n",
    "    \"Actor2Name\", \"Actor2CountryCode\", \"Actor2KnownGroupCode\", \"Actor2EthnicCode\", \"Actor2Religion1Code\", \n",
    "    \"Actor2Religion2Code\", \"Actor2Type1Code\", \"Actor2Type2Code\", \"Actor2Type3Code\", \"IsRootEvent\", \n",
    "    \"EventCode\", \"EventBaseCode\", \"EventRootCode\", \"QuadClass\", \"GoldsteinScale\", \"NumMentions\", \n",
    "    \"NumSources\", \"NumArticles\", \"AvgTone\", \"Actor1Geo_Type\", \"Actor1Geo_FullName\", \"Actor1Geo_CountryCode\", \n",
    "    \"Actor1Geo_ADM1Code\", \"Actor1Geo_Lat\", \"Actor1Geo_Long\", \"Actor1Geo_FeatureID\", \"Actor2Geo_Type\", \n",
    "    \"Actor2Geo_FullName\", \"Actor2Geo_CountryCode\", \"Actor2Geo_ADM1Code\", \"Actor2Geo_Lat\", \"Actor2Geo_Long\", \n",
    "    \"Actor2Geo_FeatureID\", \"ActionGeo_Type\", \"ActionGeo_FullName\", \"ActionGeo_CountryCode\", \"ActionGeo_ADM1Code\", \n",
    "    \"ActionGeo_Lat\", \"ActionGeo_Long\", \"ActionGeo_FeatureID\", \"DATEADDED\", \"SOURCEURL\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to download the data and process it (had to include some processing due to issues with the files being too large overall to download all of them before processing) : download_and_process_zip found in the [data_collection.py](../data_collection.py) file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funtion to build yearly summaries of the processed daily data: process_year_data found in the same file as the function above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Even though the data is partially processed, it will be saved in a raw data folder as we will further process the data in NB02. Some processing was nessecary in this notebook to make the file sizes smaller, but this is minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for year 2013...\n",
      "File not found (404): http://data.gdeltproject.org/events/20130101.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130102.export.CSV.zip\n",
      "File not found (404): http://data.gdeltproject.org/events/20130103.export.CSV.zip\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Process data from 2014 to 2023\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mprocess_year_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_year\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2013\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_year\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2023\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m, in \u001b[0;36mprocess_year_data\u001b[0;34m(start_year, end_year, output_dir)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m df_filtered \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m             year_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([year_data, df_filtered], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 25\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Delay to avoid excessive requests\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiles_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalendar\u001b[38;5;241m.\u001b[39mmonth_name[month]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Print files found for the month\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Save the year's data to a CSV file\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Process data from 2014 to 2023 using the download_and_process_zip and process_year_data functions\n",
    "process_year_data(start_year=2013, end_year=2023)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The function above will take at least 4 or 5 hours to get the data from. It shows up with an error in this Notebook because we have paused the operations. Furthermore, there are no files found for the first 3 months of 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling data for 2006 to 2013:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided it was necessary to pull this data so that we had a big enough data set and our visualisation would be able to properly demonstrate whether there is any correlation with GDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDELT column names\n",
    "GDELT_COLUMNS = [\n",
    "    \"GLOBALEVENTID\", \"SQLDATE\", \"MonthYear\", \"Year\", \"FractionDate\", \"Actor1Code\", \"Actor1Name\",\n",
    "    \"Actor1CountryCode\", \"Actor1KnownGroupCode\", \"Actor1EthnicCode\", \"Actor1Religion1Code\",\n",
    "    \"Actor1Religion2Code\", \"Actor1Type1Code\", \"Actor1Type2Code\", \"Actor1Type3Code\", \"Actor2Code\",\n",
    "    \"Actor2Name\", \"Actor2CountryCode\", \"Actor2KnownGroupCode\", \"Actor2EthnicCode\", \"Actor2Religion1Code\",\n",
    "    \"Actor2Religion2Code\", \"Actor2Type1Code\", \"Actor2Type2Code\", \"Actor2Type3Code\", \"IsRootEvent\",\n",
    "    \"EventCode\", \"EventBaseCode\", \"EventRootCode\", \"QuadClass\", \"GoldsteinScale\", \"NumMentions\",\n",
    "    \"NumSources\", \"NumArticles\", \"AvgTone\", \"Actor1Geo_Type\", \"Actor1Geo_FullName\", \"Actor1Geo_CountryCode\",\n",
    "    \"Actor1Geo_ADM1Code\", \"Actor1Geo_Lat\", \"Actor1Geo_Long\", \"Actor1Geo_FeatureID\", \"Actor2Geo_Type\",\n",
    "    \"Actor2Geo_FullName\", \"Actor2Geo_CountryCode\", \"Actor2Geo_ADM1Code\", \"Actor2Geo_Lat\",\n",
    "    \"Actor2Geo_Long\", \"Actor2Geo_FeatureID\", \"ActionGeo_Type\", \"ActionGeo_FullName\",\n",
    "    \"ActionGeo_CountryCode\", \"ActionGeo_ADM1Code\", \"ActionGeo_Lat\", \"ActionGeo_Long\",\n",
    "    \"ActionGeo_FeatureID\", \"DATEADDED\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress specific warnings related to DtypeWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.DtypeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for year 2006...\n",
      "Year 2006 data saved to ../../data/raw/2006_protest_data.csv\n",
      "Processing data for year 2007...\n",
      "Year 2007 data saved to ../../data/raw/2007_protest_data.csv\n",
      "Processing data for year 2008...\n",
      "Year 2008 data saved to ../../data/raw/2008_protest_data.csv\n",
      "Processing data for year 2009...\n",
      "Year 2009 data saved to ../../data/raw/2009_protest_data.csv\n",
      "Processing data for year 2010...\n",
      "Year 2010 data saved to ../../data/raw/2010_protest_data.csv\n",
      "Processing data for year 2011...\n",
      "Year 2011 data saved to ../../data/raw/2011_protest_data.csv\n",
      "Processing data for year 2012...\n",
      "Year 2012 data saved to ../../data/raw/2012_protest_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Run the full processing from 2006 to 2013 using the Process_year_data function\n",
    "Process_year_data(2006, 2012)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The function above takes around 25 minutes to process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
